# -*- coding: utf-8 -*-
"""Cattle_weight_detection_system

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CO5iehx1rpRJcVA6d11f6RLoRhsSo4pQ

**Zip file extraction**
"""

import os
import zipfile
from pathlib import Path

def unzip_and_structure(zip_path: str, extract_to: str):
    """
    Unzip the given zip file into the specified folder and
    create a directory structure mirrored as needed.
    """
    zip_path = Path(zip_path)
    extract_to = Path(extract_to)
    if not zip_path.exists():
        raise FileNotFoundError(f"Zip file not found: {zip_path}")

    # Create extraction directory if it doesn't exist
    extract_to.mkdir(parents=True, exist_ok=True)

    # Unzip
    with zipfile.ZipFile(zip_path, 'r') as zf:
        zf.extractall(extract_to)

    print(f"Extracted all files to {extract_to}")

# Define the zip file path and extraction folder
zip_file_path = "/content/drive/MyDrive/cattle_resized_images.zip"
extract_folder = "/content/Cattle_resized_data"

# Unzip the file
unzip_and_structure(zip_file_path, extract_folder)

print("✅ Zip file extracted and directory created.")

"""**Total number of images**"""

import os

def count_images_in_folder(folder_path):
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')
    count = 0

    for root, dirs, files in os.walk(folder_path):
        for file in files:
            if file.lower().endswith(image_extensions):
                count += 1

    return count

# Example usage:
dataset_path = '/content/Cattle_resized_data'  # <-- change this
total_images = count_images_in_folder(dataset_path)

print(f"Total number of images: {total_images}")

"""**Extracts image metadata and mask paths**"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf
import matplotlib.pyplot as plt

# Set seed for reproducibility
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Root directory
dataset_dir = "/content/Cattle_resized_data"
data = []

# Parse images and extract metadata
for root, dirs, files in os.walk(dataset_dir):
    if os.path.basename(root).lower() == "images":
        for filename in files:
            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                parts = filename.split('_')
                try:
                    if len(parts) == 5:
                        if "b4" in parts[1].lower():
                            view = parts[2].lower()
                            weight = float(parts[3])
                            gender = parts[4].split('.')[0]
                        else:
                            view = parts[1].lower()
                            weight = float(parts[2])
                            gender = parts[4].split('.')[0]
                    elif len(parts) == 4:
                        view = parts[1].lower()
                        weight = float(parts[2])
                        gender = parts[3].split('.')[0]
                    else:
                        continue

                    image_path = os.path.join(root, filename)
                    annotation_path = os.path.join(root.replace("images", "annotations"), filename + "___fuse.png")

                    if os.path.exists(annotation_path):
                        data.append((image_path, annotation_path, weight, view, gender))
                except Exception as e:
                    continue

# Create DataFrame
df = pd.DataFrame(data, columns=["image_path", "mask_path", "weight", "view", "gender"])
print(f"✅ Total valid image-mask pairs found: {len(df)}")

"""**Tensorflow installation**"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tensorflow

"""**Data splitting**"""

# Split data into training, validation, and testing sets (60% train, 20% validation, 20% test)
from sklearn.model_selection import train_test_split

# First split: 80% temp (train+val), 20% test
temp_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['view'])

# Second split: 75% train from temp (60% of total), 25% val from temp (20% of total)
train_df, val_df = train_test_split(temp_df, test_size=0.25, random_state=SEED, stratify=temp_df['view'])


# Check sizes
print(f"Train size: {len(train_df)}")
print(f"Validation size: {len(val_df)}")
print(f"Test size: {len(test_df)}")

"""**• Reads and resizes both photo and mask to 224×224.**

**• Normalizes pixel values to [0,1].**

**• Extracts and thresholds the green channel of the mask to make a clean, binary potrait of the kettle.**
"""

# Image size
IMG_SIZE = (224, 224)

def decode_and_resize(image_path, target_size=IMG_SIZE):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, target_size)
    return img

def preprocess(image_path, mask_path):
    image = decode_and_resize(image_path)
    mask_raw = decode_and_resize(mask_path)

    # Normalize image
    image = tf.cast(image, tf.float32) / 255.0
    mask_raw = tf.cast(mask_raw, tf.float32) / 255.0

    # Extract green channel only (kettle)
    kettle_mask = mask_raw[:, :, 1]  # Green channel

    # Threshold the green channel to make binary mask
    kettle_mask = tf.where(kettle_mask > 0.5, 1.0, 0.0)  # binary mask

    # Expand dims to match shape (H, W, 1)
    kettle_mask = tf.expand_dims(kettle_mask, axis=-1)

    # Optionally apply mask to image
    masked_image = image * kettle_mask

    return image, kettle_mask  # For segmentation task

"""**Creating directory of splitted data**"""

import os
import shutil
from tqdm import tqdm

# Base directory for split datasets
split_dir = "/content/cattle_train_test_split"

# If directory already exists, remove and recreate
if os.path.exists(split_dir):
    shutil.rmtree(split_dir)
    print(f"Removed existing directory: {split_dir}")

# Define split folders
for split in ["train", "val", "test"]:
    for sub in ["images", "masks"]:
        os.makedirs(os.path.join(split_dir, split, sub), exist_ok=True)

def copy_split_data(df, split):
    for _, row in tqdm(df.iterrows(), total=len(df), desc=f"Copying {split}"):
        img_src = row["image_path"]
        mask_src = row["mask_path"]

        img_dst = os.path.join(split_dir, split, "images", os.path.basename(img_src))
        mask_dst = os.path.join(split_dir, split, "masks", os.path.basename(mask_src))

        shutil.copy(img_src, img_dst)
        shutil.copy(mask_src, mask_dst)

# Copy train, val, test data
copy_split_data(train_df, "train")
copy_split_data(val_df, "val")
copy_split_data(test_df, "test")

print("✅ All splits copied into:", split_dir)

"""**This code preprocesses images and masks and creates batched TensorFlow Datasets for model training.**"""

import tensorflow as tf

# Image size
IMG_SIZE = (224, 224)

def decode_and_resize(image_path, target_size=IMG_SIZE):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, target_size)
    return img

def resize_img_mask(image_path, mask_path, target_size=IMG_SIZE):
    image = decode_and_resize(image_path, target_size)
    mask_raw = decode_and_resize(mask_path, target_size)

    # Normalize image
    image = tf.cast(image, tf.float32) / 255.0
    mask_raw = tf.cast(mask_raw, tf.float32) / 255.0

    # Extract green channel only (kettle)
    kettle_mask = mask_raw[:, :, 1]  # Green channel

    # Threshold the green channel to make binary mask
    kettle_mask = tf.where(kettle_mask > 0.5, 1.0, 0.0)  # binary mask

    # Expand dims to match shape (H, W, 1)
    kettle_mask = tf.expand_dims(kettle_mask, axis=-1)

    return image, kettle_mask


# Create TensorFlow Datasets from DataFrames
train_ds = tf.data.Dataset.from_tensor_slices((train_df['image_path'], train_df['mask_path']))
val_ds   = tf.data.Dataset.from_tensor_slices((val_df['image_path'], val_df['mask_path']))
test_ds  = tf.data.Dataset.from_tensor_slices((test_df['image_path'], test_df['mask_path']))

# Apply resizing and preprocessing to all datasets
train_ds = train_ds.map(resize_img_mask, num_parallel_calls=tf.data.AUTOTUNE)
val_ds   = val_ds.map(resize_img_mask, num_parallel_calls=tf.data.AUTOTUNE)
test_ds  = test_ds.map(resize_img_mask, num_parallel_calls=tf.data.AUTOTUNE)


BATCH_SIZE = 8  # you can tune this depending on GPU memory

train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_ds   = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_ds  = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

"""**Efficientnetb4(encoder)_attention_unet Model training(for segmentation)**"""

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import EfficientNetB4

# Input size
IMG_SIZE = (224, 224, 3)

# Dice coefficient
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

def dice_loss(y_true, y_pred):
    return 1 - dice_coef(y_true, y_pred)

# Attention gate
def attention_gate(x, g, inter_channels):
    theta_x = layers.Conv2D(inter_channels, 1, padding='same')(x)
    phi_g = layers.Conv2D(inter_channels, 1, padding='same')(g)
    add = layers.Add()([theta_x, phi_g])
    relu = layers.Activation('relu')(add)
    psi = layers.Conv2D(1, 1, padding='same')(relu)
    sigmoid = layers.Activation('sigmoid')(psi)
    return layers.Multiply()([x, sigmoid])

# EfficientNet-B4 Attention U-Net
def efficientnetb4_attention_unet(input_size=IMG_SIZE):
    inputs = tf.keras.Input(shape=input_size)

    # Backbone from scratch
    base_model = EfficientNetB4(include_top=False, weights=None, input_tensor=inputs)

    # Encoder skip connections
    skip_names = ["block2a_expand_activation", "block3a_expand_activation",
                  "block4a_expand_activation", "block6a_expand_activation"]
    skips = [base_model.get_layer(name).output for name in skip_names]

# Bottleneck
    x = base_model.output

    # Decoder with attention gates
    for i in reversed(range(len(skips))):
        x = layers.UpSampling2D()(x)
        att = attention_gate(skips[i], x, skips[i].shape[-1])
        x = layers.Concatenate()([x, att])
        x = layers.Conv2D(256 // (2**i), 3, padding='same', activation='relu')(x)
        x = layers.Conv2D(256 // (2**i), 3, padding='same', activation='relu')(x)

    # Add resizing layer before the final output
    x = layers.Resizing(IMG_SIZE[0], IMG_SIZE[1])(x)

    # Final output layer
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(x)


    model = Model(inputs, outputs)
    return model

# Instantiate model
model = efficientnetb4_attention_unet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])
model.summary()

import matplotlib.pyplot as plt
import tensorflow as tf

# Make sure you have defined:
# - efficientnetb4_attention_unet()
# - dice_coef

# Instantiate the EfficientNet-B4 Attention U-Net
model = efficientnetb4_attention_unet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])

# Callbacks
checkpoint_path = "/content/model.keras"
checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(
    checkpoint_path, save_best_only=True, monitor='val_dice_coef', mode='max', verbose=1
)

earlystop_cb = tf.keras.callbacks.EarlyStopping(
    monitor='val_dice_coef', mode='max', patience=5, restore_best_weights=True, verbose=1
)

# Train the model
history = model.fit(
    train_ds,            # your training dataset (tf.data.Dataset)
    validation_data=val_ds,  # your validation dataset
    epochs=15,
    callbacks=[checkpoint_cb, earlystop_cb]
)

# Plot loss and dice coefficient curves
plt.figure(figsize=(12,4))

plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Curve')

plt.subplot(1,2,2)
plt.plot(history.history['dice_coef'], label='Train Dice')
plt.plot(history.history['val_dice_coef'], label='Val Dice')
plt.xlabel('Epoch')
plt.ylabel('Dice Coefficient')
plt.legend()
plt.title('Dice Coefficient Curve')

plt.show()

print(f"Best model saved at: {checkpoint_path}")

# Print the last training Dice Coefficient in percentage
print(f"\nLast Training Dice Coefficient: {history.history['dice_coef'][-1]*100:.2f}%")

"""**Model loading**"""

import tensorflow as tf

# Define the path to the saved model in Google Drive
model_save_path = "/content/drive/MyDrive/attention_unet_model.keras" # Update this path if you saved it elsewhere

# Make sure the custom dice_coef function is defined
def dice_coef(y_true, y_pred, smooth=1e-6):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

# Load the model, specifying the custom object and disabling safe mode for Lambda layers
try:
    loaded_model = tf.keras.models.load_model(
        model_save_path,
        # Add custom objects if any (like dice_coef)
        custom_objects={'dice_coef': dice_coef},
        safe_mode=False # Disable safe mode for deserializing custom lambda layers
    )
    print("Model loaded successfully!")

except Exception as e:
    print(f"Error loading model: {e}")
    print("Please ensure Google Drive is mounted and the model file exists at the specified path.")
    print("Also, make sure the 'dice_coef' function is defined in a previous cell.")

"""**Cattle weight distribution**"""

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize the distribution of 'weight'
plt.figure(figsize=(8, 6))
sns.histplot(df['weight'], kde=True)
plt.title('Distribution of Cattle Weight')
plt.xlabel('Weight (kg)')
plt.ylabel('Frequency')
plt.show()

"""**Average weight by gender**"""

import matplotlib.pyplot as plt
import seaborn as sns

# Analyze the relationship between 'weight' and 'gender' by comparing average weight
average_weight_by_gender = df.groupby('gender')['weight'].mean()

print("Average weight by gender:")
display(average_weight_by_gender)

# Create a bar plot of average weight by gender
plt.figure(figsize=(6, 4))
sns.barplot(x=average_weight_by_gender.index, y=average_weight_by_gender.values)
plt.title('Average Cattle Weight by Gender')
plt.xlabel('Gender')
plt.ylabel('Average Weight (kg)')
plt.show()

"""**Visualizes the original image, ground truth mask, and predicted mask for a batch of test data using the loaded segmentation model.**"""

# 2. Perform inference on a few test images and visualize the results
import matplotlib.pyplot as plt

# Get a batch of test data
for images, true_masks in test_ds.take(1): # Take one batch
    predictions = loaded_model.predict(images)

    plt.figure(figsize=(15, len(images) * 5))
    for i in range(len(images)):
        # Original Image
        plt.subplot(len(images), 3, i * 3 + 1)
        plt.imshow(images[i])
        plt.title("Original Image")
        plt.axis('off')

        # Ground Truth Mask
        plt.subplot(len(images), 3, i * 3 + 2)
        plt.imshow(tf.squeeze(true_masks[i]), cmap='gray')
        plt.title("Ground Truth Mask")
        plt.axis('off')

        # Predicted Mask
        plt.subplot(len(images), 3, i * 3 + 3)
        plt.imshow(tf.squeeze(predictions[i]), cmap='gray')
        plt.title("Predicted Mask")
        plt.axis('off')

    plt.tight_layout()
    plt.show()

"""**Removes rows with missing values in the 'weight' column from the DataFrame**



"""

df.dropna(subset=['weight'], inplace=True)
print(f"Number of rows after dropping missing weight values: {df.shape[0]}")

"""**Columns present in dataset**"""

print(df.columns)

"""**XG-Boost regression**"""

import xgboost as xgb
from sklearn.metrics import mean_absolute_error

# Initialize and train the XGBoost Regressor model
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', # Regression task
                             n_estimators=1000,            # Number of boosting rounds
                             learning_rate=0.05,           # Step size shrinkage
                             max_depth=7,                  # Maximum depth of trees
                             subsample=0.7,                # Fraction of samples for fitting the trees
                             colsample_bytree=0.7,         # Fraction of features for fitting the trees
                             random_state=SEED,            # for reproducibility
                             n_jobs=-1,                    # Use all available cores
                             early_stopping_rounds=10)     # Stop if no improvement for 10 rounds

print("Training XGBoost model...")
xgb_model.fit(train_features, train_weights,
              eval_set=[(val_features, val_weights)]) # Use validation set for early stopping


print("✅ XGBoost model training complete.")

"""**MAE of XGBoost model**"""

from sklearn.metrics import mean_absolute_error

# Make predictions on the test set
print("Making predictions on the test dataset...")
test_predictions = xgb_model.predict(test_features)

# Evaluate the model using Mean Absolute Error (MAE)
mae = mean_absolute_error(test_weights, test_predictions)

print(f"✅ XGBoost Model Test Mean Absolute Error (MAE): {mae:.4f}")

"""**Weight prediction with respect to True weights using XGBoost model**"""

import matplotlib.pyplot as plt
import numpy as np

# Select a few images from the test set for visualization
num_images_to_show = 5
sample_indices = np.random.choice(len(test_df), num_images_to_show, replace=False)

plt.figure(figsize=(10, num_images_to_show * 4))

for i, idx in enumerate(sample_indices):
    # Get the image path and ground truth weight
    image_path = test_df.iloc[idx]['image_path']
    true_weight = test_df.iloc[idx]['weight']

    # Load and preprocess the image (using the resize_image function defined earlier)
    # Need to make sure resize_image is accessible or redefine it here
    # Assuming resize_image is accessible from a previous cell
    image = tf.io.read_file(image_path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, IMG_SIZE_RESIZE)
    image = tf.cast(image, tf.float32) / 255.0

    # Add batch dimension for prediction
    image_batch = tf.expand_dims(image, axis=0)

    # Get the corresponding features for the selected image
    # Assuming test_features and test_df are aligned by index after splitting
    image_features = test_features[idx]

    # Predict the weight using the XGBoost model
    predicted_weight = xgb_model.predict(image_features.reshape(1, -1))[0] # Reshape for single prediction


    plt.subplot(num_images_to_show, 1, i + 1)
    plt.imshow(image)
    plt.title(f"Ground Truth Weight: {true_weight:.2f} kg | Predicted Weight (XGBoost): {predicted_weight:.2f} kg")
    plt.axis('off')

plt.tight_layout()
plt.show()

"""**RMSE of the XGBoost model**"""

from sklearn.metrics import mean_squared_error
import numpy as np

# True weights from the test DataFrame
y_true = test_df['weight'].values

# Predictions for all test features
y_pred = xgb_model.predict(test_features)

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(y_true, y_pred))

print(f"Root Mean Squared Error (RMSE): {rmse:.4f}")

"""**Plots predicted vs. true weights with a reference line for perfect predictions**"""

import matplotlib.pyplot as plt
import numpy as np

# Create scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(test_weights, test_predictions, alpha=0.5)

# Add diagonal line for perfect predictions
min_weight = min(np.min(test_weights), np.min(test_predictions))
max_weight = max(np.max(test_weights), np.max(test_predictions))
plt.plot([min_weight, max_weight], [min_weight, max_weight], color='red', linestyle='--')

plt.xlabel("True Weight (kg)")
plt.ylabel("Predicted Weight (kg)")
plt.title("True vs. Predicted Weights (XGBoost)")
plt.grid(True)
plt.show()

"""**Plots a histogram showing the distribution of absolute prediction errors**"""

# Calculate absolute errors
abs_errors = abs(test_weights - test_predictions)

# Add absolute errors to test_df
test_df['absolute_error'] = abs_errors

# Analyze the distribution of absolute errors
plt.figure(figsize=(8, 6))
plt.hist(abs_errors, bins=50, edgecolor='black')
plt.title('Distribution of Absolute Errors')
plt.xlabel('Absolute Error (kg)')
plt.ylabel('Frequency')
plt.show()

"""**Calculates and displays the average absolute prediction error grouped by view and gender**"""

# Group by 'view' and calculate average absolute error
average_error_by_view = test_df.groupby('view')['absolute_error'].mean()

print("Average absolute error by view:")
display(average_error_by_view)

# Group by 'gender' and calculate average absolute error
average_error_by_gender = test_df.groupby('gender')['absolute_error'].mean()

print("\nAverage absolute error by gender:")
display(average_error_by_gender)

"""## Feature engineering

**The code extracts EfficientNetB4 image features, computes binary mask areas, and combines them with corresponding weights for training, validation, and test datasets.**
"""

from tensorflow.keras.applications import EfficientNetB4
from tensorflow.keras.models import Model
import numpy as np
from tqdm import tqdm
import tensorflow as tf

# Define the image size for resizing
IMG_SIZE_RESIZE = (224, 224)

# Load pre-trained EfficientNetB4 without the top classification layer
base_model = EfficientNetB4(weights='imagenet', include_top=False, pooling='avg')

# Create a model that outputs the global average pooled features
feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)


# Function to preprocess images and extract features
def extract_features(dataframe, feature_extractor):
    features = []
    weights = []
    for index, row in tqdm(dataframe.iterrows(), total=len(dataframe)):
        image_path = row['image_path']
        mask_path = row['mask_path'] # Get the mask path
        weight = row['weight']

        # Preprocess image using the previously defined function
        # resize_img_mask returns (image, mask), we only need the image
        image, _ = resize_img_mask(image_path, mask_path) # Pass both paths

        # Add batch dimension for prediction
        image = tf.expand_dims(image, axis=0)

        # Extract features
        image_features = feature_extractor.predict(image, verbose=0)

        features.append(image_features[0]) # Remove batch dimension
        weights.append(weight)

    return np.array(features), np.array(weights)

# Function to resize both image and mask - ensuring correct IMG_SIZE is used for resizing
def resize_img_mask(image_path, mask_path, target_size=IMG_SIZE_RESIZE):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, target_size) # Use IMG_SIZE_RESIZE
    image = tf.cast(image, tf.float32) / 255.0 # Normalize image

    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=3) # Assuming mask is PNG
    mask = tf.image.resize(mask, target_size) # Use IMG_SIZE_RESIZE
    mask = tf.cast(mask, tf.float32) / 255.0 # Normalize mask

    # Extract green channel only (kettle)
    kettle_mask = mask[:, :, 1]  # Green channel

    # Threshold the green channel to make binary mask
    kettle_mask = tf.where(kettle_mask > 0.5, 1.0, 0.0)  # binary mask

    # Expand dims to match shape (H, W, 1)
    kettle_mask = tf.expand_dims(kettle_mask, axis=-1)

    return image, kettle_mask


# Extract features and weights for each split
print("Extracting features for training data...")
train_features, train_weights = extract_features(train_df, feature_extractor)

print("Extracting features for validation data...")
val_features, val_weights = extract_features(val_df, feature_extractor)

print("Extracting features for test data...")
test_features, test_weights = extract_features(test_df, feature_extractor)

print("✅ Features extracted and stored.")
print(f"Train features shape: {train_features.shape}, Train weights shape: {train_weights.shape}")
print(f"Validation features shape: {val_features.shape}, Validation weights shape: {val_weights.shape}")
print(f"Test features shape: {test_features.shape}, Test weights shape: {test_weights.shape}")

"""CNN regression"""

import tensorflow as tf
from tensorflow.keras import layers, Model

# Define the input shape for the CNN regression model
# The input will be the masked image output from the segmentation model
# It will have the same size as the input image (224, 224) and 3 channels
INPUT_SHAPE_CNN = (IMG_SIZE[0], IMG_SIZE[1], 3) # Use original image size

def build_cnn_regression_model(input_shape=INPUT_SHAPE_CNN):
    inputs = tf.keras.Input(shape=input_shape)

    # Add convolutional layers
    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = layers.MaxPooling2D((2, 2))(x)

    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2))(x)

    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = layers.MaxPooling2D((2, 2))(x)

    # Flatten the output for the dense layers
    x = layers.Flatten()(x)

    # Add dense layers
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dropout(0.5)(x)

    # Output layer for regression (predicting weight - a single value)
    outputs = layers.Dense(1)(x)

    model = Model(inputs, outputs)
    return model

# Build the CNN regression model
cnn_regression_model = build_cnn_regression_model()

# Compile the model for regression
cnn_regression_model.compile(optimizer='adam',
                             loss='mean_squared_error', # MSE is common for regression
                             metrics=['mean_absolute_error']) # MAE is also a useful metric

cnn_regression_model.summary()

"""**Loads image and mask paths along with weight, view, and gender information from the dataset directory into a pandas DataFrame for further processing.**"""

import os
import pandas as pd
import numpy as np

# Set seed for reproducibility
SEED = 42
np.random.seed(SEED)

# Root directory
dataset_dir = "/content/Cattle_resized_data"
data = []

# Parse images and extract metadata
for root, dirs, files in os.walk(dataset_dir):
    if os.path.basename(root).lower() == "images":
        for filename in files:
            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                parts = filename.split('_')
                try:
                    if len(parts) == 5:
                        if "b4" in parts[1].lower():
                            view = parts[2].lower()
                            weight = float(parts[3])
                            gender = parts[4].split('.')[0]
                        else:
                            view = parts[1].lower()
                            weight = float(parts[2])
                            gender = parts[4].split('.')[0]
                    elif len(parts) == 4:
                        view = parts[1].lower()
                        weight = float(parts[2])
                        gender = parts[3].split('.')[0]
                    else:
                        continue

                    image_path = os.path.join(root, filename)
                    annotation_path = os.path.join(root.replace("images", "annotations"), filename + "___fuse.png")

                    if os.path.exists(annotation_path):
                        data.append((image_path, annotation_path, weight, view, gender))
                except Exception as e:
                    continue

# Create DataFrame
df = pd.DataFrame(data, columns=["image_path", "mask_path", "weight", "view", "gender"])
print(f"✅ Total valid image-mask pairs found: {len(df)}")

# Define image size (assuming it's the same as the segmentation model)
IMG_SIZE = (224, 224)

BATCH_SIZE = 8  # you can tune this depending on GPU memory

# Split data into training, validation, and testing sets (60% train, 20% validation, 20% test)
from sklearn.model_selection import train_test_split

# First split: 80% temp (train+val), 20% test
temp_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['view'])

# Second split: 75% train from temp (60% of total), 25% val from temp (20% of total)
train_df, val_df = train_test_split(temp_df, test_size=0.25, random_state=SEED, stratify=temp_df['view'])


# Check sizes
print(f"Train size: {len(train_df)}")
print(f"Validation size: {len(val_df)}")
print(f"Test size: {len(test_df)}")

import tensorflow as tf

# Image size
IMG_SIZE = (224, 224)

def decode_and_resize(image_path, target_size=IMG_SIZE):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, target_size)
    return img

def preprocess(image_path, mask_path):
    image = decode_and_resize(image_path)
    mask_raw = decode_and_resize(mask_path)

    # Normalize image
    image = tf.cast(image, tf.float32) / 255.0
    mask_raw = tf.cast(mask_raw, tf.float32) / 255.0

    # Extract green channel only (kettle)
    kettle_mask = mask_raw[:, :, 1]  # Green channel

    # Threshold the green channel to make binary mask
    kettle_mask = tf.where(kettle_mask > 0.5, 1.0, 0.0)  # binary mask

    # Expand dims to match shape (H, W, 1)
    kettle_mask = tf.expand_dims(kettle_mask, axis=-1)

    # Optionally apply mask to image
    masked_image = image * kettle_mask

    return image, kettle_mask  # For segmentation task

"""**Defines functions to decode, resize, and preprocess images and masks, including creating a binary mask from the green channel for segmentation tasks.**"""

import tensorflow as tf

# Function to apply the segmentation model and get the masked image
def get_masked_image(image_path, mask_path, weight):
    # Preprocess image and mask using the existing preprocess function
    # This function returns the normalized image and the binary kettle mask
    image, kettle_mask = preprocess(image_path, mask_path)

    # Apply the binary mask to the original image
    masked_image = image * kettle_mask

    # Return the masked image and the weight
    return masked_image, weight

# Create TensorFlow Datasets for the CNN regression model
# Map the get_masked_image function to each dataset
train_cnn_ds = tf.data.Dataset.from_tensor_slices((train_df['image_path'], train_df['mask_path'], train_df['weight']))
train_cnn_ds = train_cnn_ds.map(get_masked_image, num_parallel_calls=tf.data.AUTOTUNE)
train_cnn_ds = train_cnn_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)


val_cnn_ds = tf.data.Dataset.from_tensor_slices((val_df['image_path'], val_df['mask_path'], val_df['weight']))
val_cnn_ds = val_cnn_ds.map(get_masked_image, num_parallel_calls=tf.data.AUTOTUNE)
val_cnn_ds = val_cnn_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)


test_cnn_ds = tf.data.Dataset.from_tensor_slices((test_df['image_path'], test_df['mask_path'], test_df['weight']))
test_cnn_ds = test_cnn_ds.map(get_masked_image, num_parallel_calls=tf.data.AUTOTUNE)
test_cnn_ds = test_cnn_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

print("✅ TensorFlow Datasets for CNN regression created.")

"""**CNN training**"""

# Train the CNN regression model
epochs = 20 # You can adjust the number of epochs

history_cnn = cnn_regression_model.fit(
    train_cnn_ds,
    validation_data=val_cnn_ds,
    epochs=epochs
)

# Define the path to save the CNN regression model
cnn_model_save_path = "/content/cnn_regression_model.keras"

# Save the trained CNN regression model
cnn_regression_model.save(cnn_model_save_path)

print(f"✅ CNN regression model saved to: {cnn_model_save_path}")

"""**Loads the saved CNN regression model and uses it to predict weights for the images in the test dataset.**"""

import tensorflow as tf

# Define the path to the saved CNN regression model
cnn_model_save_path = "/content/cnn_regression_model.keras"

# Load the saved CNN regression model
loaded_cnn_model = tf.keras.models.load_model(cnn_model_save_path)

# Make predictions on the test set
print("Making predictions on the test dataset with the CNN regression model...")
test_predictions_cnn = loaded_cnn_model.predict(test_cnn_ds)

print("✅ Predictions made with CNN regression model.")

"""**Visualizes the original image, ground truth mask, and predicted mask for a batch of test data using the loaded segmentation model.**"""

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

# Assuming loaded_cnn_model and test_cnn_ds are available from previous cells

# Select a few images and true weights from the test dataset for visualization
# We can iterate through the test_cnn_ds to get batches
num_batches_to_show = 1 # Show predictions for the first batch
num_images_per_batch = BATCH_SIZE # Assuming BATCH_SIZE is defined

plt.figure(figsize=(10, num_images_per_batch * 4))

for batch_idx, (masked_images, true_weights) in enumerate(test_cnn_ds.take(num_batches_to_show)):
    # Make predictions using the loaded CNN model
    predicted_weights = loaded_cnn_model.predict(masked_images).squeeze() # Use squeeze to remove single-dimensional entries

    for i in range(masked_images.shape[0]):
        # Display the masked image
        plt.subplot(num_images_per_batch, 1, i + 1)
        plt.imshow(masked_images[i].numpy()) # Convert tensor to numpy for imshow
        plt.title(f"Ground Truth Weight: {true_weights[i].numpy():.2f} kg | Predicted Weight (CNN): {predicted_weights[i]:.2f} kg") # Convert tensor to numpy
        plt.axis('off')

    if batch_idx == num_batches_to_show - 1:
        break # Stop after visualizing the specified number of batches

plt.tight_layout()
plt.show()

# Assuming test_df is available
test_weights = test_df['weight'].values
print("✅ test_weights defined.")

# Re-create the DataFrame df
import os
import pandas as pd
import numpy as np

# Set seed for reproducibility
SEED = 42
np.random.seed(SEED)

# Root directory
dataset_dir = "/content/Cattle_resized_data"
data = []

# Parse images and extract metadata
for root, dirs, files in os.walk(dataset_dir):
    if os.path.basename(root).lower() == "images":
        for filename in files:
            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                parts = filename.split('_')
                try:
                    if len(parts) == 5:
                        if "b4" in parts[1].lower():
                            view = parts[2].lower()
                            weight = float(parts[3])
                            gender = parts[4].split('.')[0]
                        else:
                            view = parts[1].lower()
                            weight = float(parts[2])
                            gender = parts[4].split('.')[0]
                    elif len(parts) == 4:
                        view = parts[1].lower()
                        weight = float(parts[2])
                        gender = parts[3].split('.')[0]
                    else:
                        continue

                    image_path = os.path.join(root, filename)
                    annotation_path = os.path.join(root.replace("images", "annotations"), filename + "___fuse.png")

                    if os.path.exists(annotation_path):
                        data.append((image_path, annotation_path, weight, view, gender))
                except Exception as e:
                    continue

# Create DataFrame
df = pd.DataFrame(data, columns=["image_path", "mask_path", "weight", "view", "gender"])
print(f"✅ Total valid image-mask pairs found: {len(df)}")

# Split data into training, validation, and testing sets (60% train, 20% validation, 20% test)
from sklearn.model_selection import train_test_split

# First split: 80% temp (train+val), 20% test
temp_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['view'])

# Second split: 75% train from temp (60% of total), 25% val from temp (20% of total)
train_df, val_df = train_test_split(temp_df, test_size=0.25, random_state=SEED, stratify=temp_df['view'])


# Check sizes
print(f"Train size: {len(train_df)}")
print(f"Validation size: {len(val_df)}")
print(f"Test size: {len(test_df)}")

"""**Defines a function to build a regression model using a pre-trained EfficientNetB4 backbone with added dense layers, allowing for fine-tuning of a specified number of layers.**"""

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import EfficientNetB4

# Input size (same as the segmentation model)
IMG_SIZE_REGRESSION = (224, 224, 3)

def efficientnetb4_regression_pretrained(input_size=IMG_SIZE_REGRESSION, trainable_layers=-1):
    inputs = tf.keras.Input(shape=input_size)

    # Load pre-trained EfficientNetB4 backbone
    # Use weights='imagenet' to load pre-trained weights
    # include_top=False to remove the classification head
    base_model = EfficientNetB4(include_top=False, weights='imagenet', input_tensor=inputs)

    # Freeze all layers initially
    base_model.trainable = False

    # Unfreeze a specified number of layers from the top
    if trainable_layers > 0:
      for layer in base_model.layers[-trainable_layers:]:
        layer.trainable = True
    elif trainable_layers == -1: # Unfreeze all layers
      base_model.trainable = True


    # Add global average pooling to get a single vector representation
    x = layers.GlobalAveragePooling2D()(base_model.output)

    # Add dense layers for regression
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dropout(0.5)(x)

    # Output layer for regression (predicting weight - a single value)
    outputs = layers.Dense(1)(x)

    model = Model(inputs, outputs)
    return model

# Instantiate the pre-trained model with a regression head, unfreezing some layers
# You can adjust 'trainable_layers' to unfreeze more or fewer layers.
# Set trainable_layers=-1 to unfreeze all layers.
regression_model_refined = efficientnetb4_regression_pretrained(trainable_layers=20) # Example: unfreeze the last 20 layers


# Compile the model for regression
# Use a smaller learning rate for fine-tuning
regression_model_refined.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
                                    loss='mean_squared_error', # MSE is common for regression
                                    metrics=['mean_absolute_error']) # MAE is also a useful metric

regression_model_refined.summary()

# Train the EfficientNetB4 regression model
epochs = 30 # You can adjust the number of epochs

history_regression_pretrained = regression_model_pretrained.fit(
    train_cnn_ds,
    validation_data=val_cnn_ds,
    epochs=epochs
)

"""**Plots the training and validation loss curves for the EfficientNetB4 regression model to visualize its training progress.**"""

import matplotlib.pyplot as plt

# Plot training and validation loss
plt.figure(figsize=(8, 6))
plt.plot(history_regression_pretrained.history['loss'], label='Train Loss')
plt.plot(history_regression_pretrained.history['val_loss'], label='Val Loss')
plt.title('EfficientNetB4 Regression Model Loss Curves (Pre-trained)')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.legend()
plt.grid(True)
plt.show()

"""**MAE and RMSE of EfficientNetB4 regression model**

"""

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np

# Make predictions on the test set
print("Making predictions on the test dataset with the EfficientNetB4 regression model...")
test_predictions_regression_pretrained = regression_model_pretrained.predict(test_cnn_ds)

# Get the true weights from the test dataset
# We need to iterate through the test_cnn_ds to get the true weights
true_weights_list = []
for images, weights in test_cnn_ds:
    true_weights_list.extend(weights.numpy())
true_weights_regression_pretrained = np.array(true_weights_list)


# Evaluate the model using Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE)
mae_regression_pretrained = mean_absolute_error(true_weights_regression_pretrained, test_predictions_regression_pretrained)
rmse_regression_pretrained = np.sqrt(mean_squared_error(true_weights_regression_pretrained, test_predictions_regression_pretrained))

print(f"\nEfficientNetB4 Regression Model Test Mean Absolute Error (MAE): {mae_regression_pretrained:.4f}")
print(f"EfficientNetB4 Regression Model Test Root Mean Squared Error (RMSE): {rmse_regression_pretrained:.4f}")

"""**Visualizes test images with their true and predicted weights from the EfficientNetB4 regression model.**"""

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

# Assuming regression_model and test_cnn_ds are available from previous cells

# Select a few images and true weights from the test dataset for visualization
num_batches_to_show = 1 # Show predictions for the first batch
num_images_per_batch = BATCH_SIZE # Assuming BATCH_SIZE is defined

plt.figure(figsize=(10, num_images_per_batch * 4))

for batch_idx, (images, true_weights) in enumerate(test_cnn_ds.take(num_batches_to_show)):
    # Make predictions using the regression model
    predicted_weights = regression_model_pretrained.predict(images).squeeze() # Use squeeze to remove single-dimensional entries

    for i in range(images.shape[0]):
        # Display the original image
        plt.subplot(num_images_per_batch, 1, i + 1)
        plt.imshow(images[i].numpy()) # Convert tensor to numpy for imshow
        plt.title(f"Ground Truth Weight: {true_weights[i].numpy():.2f} kg | Predicted Weight (EfficientNetB4 Regression): {predicted_weights[i]:.2f} kg") # Convert tensor to numpy
        plt.axis('off')

    if batch_idx == num_batches_to_show - 1:
        break # Stop after visualizing the specified number of batches

plt.tight_layout()
plt.show()